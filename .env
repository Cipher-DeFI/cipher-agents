### elizaOS Environment Variables ###
# To get started, copy this file to .env, or make a .env and add the settings you'd like to override
# Please read the comments for each of the configurations

## The only thing you ABSOLUTELY NEED to get up and running is one of the model provider keys, 
## i.e. OPENAI_API_KEY or ANTHROPIC_API_KEY, or setup the local-ai or ollama plugin
## Everything else is optional, and most settings and secrets can be configured in your agent or through the GUI
## For multi-agent, each agent will need keys for the various services it is connected to
-------------------------------
## You can use the .env or environment variables generally for shared keys, such as to model providers, 
## database, etc, with scoped keys for services such as Telegram, Discord, etc

## MODEL PROVIDER KEYS ##
## Eliza is compatible with a wide array of model providers. Many have OpenAI compatible APIs, 
## and you can use them by overriding the base URL

## NOTE: You will need a provider that provides embeddings. So even if you use Claude, you will 
## need to get embeddings using another provider, for example openai or our local-ai plugin

# OpenAI Configuration
## Use this to override the openai endpoint, for example for using together.ai, fireworks or other providers
## Optional overrides:
--------------------------------
# OPENAI_BASE_URL=
# OPENAI_SMALL_MODEL=gpt-4o-mini
# OPENAI_LARGE_MODEL=gpt-4o
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_EMBEDDING_URL=
# OPENAI_EMBEDDING_DIMENSIONS=1536
# OPENAI_IMAGE_DESCRIPTION_MODEL=gpt-4o-mini
# OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS=8192

# Anthropic Configuration
## By default in most of our starter kits, Anthropic will take precedence over OpenAI in handling requests
## Anthropic does not handle embeddings, so you may wish to use OpenAI for that, even while Claude is handling text generation
--------------------------------
ANTHROPIC_API_KEY=
# Optional overrides:
# ANTHROPIC_SMALL_MODEL=claude-3-5-haiku-latest
# ANTHROPIC_LARGE_MODEL=claude-3-5-sonnet-latest


# Ollama Configuration
## Highly recommended to use gemma3:latest for text generation
--------------------------------
# OLLAMA_API_ENDPOINT=http://localhost:11434/api
# OLLAMA_SMALL_MODEL=gemma3:latest
# OLLAMA_MEDIUM_MODEL=gemma3:latest
# OLLAMA_LARGE_MODEL=gemma3:latest


# Local AI Configuration
## REMEMBER A GOOD AMOUNT OF VRAM IS NEEDED FOR THE LARGE LOCAL MODELS
--------------------------------
# LOCAL_SMALL_MODEL=DeepHermes-3-Llama-3-3B-Preview-q4.gguf
# LOCAL_LARGE_MODEL=DeepHermes-3-Llama-3-70B-Preview-q4.gguf
# LOCAL_EMBEDDING_MODEL=bge-small-en-v1.5.Q4_K_M.gguf




# Highly recommended to use nomic-embed-text for embeddings
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text 

### DATABASE ###
# By default, Eliza will use a local pglite instance
# If you fill out POSTGRES_URL, the agent will connect to your postgres instance instead of using the local path

# You can override the pglite data directory

# Fill this out if you want to use Postgres
POSTGRES_URL=postgresql://postgres.gmegyotxoqnhffgdmrof:bUbNe5ZkGG0PywGq@aws-0-ap-southeast-1.pooler.supabase.com:6543/postgres

### LOGGING CONFIGURATION ###
# Logging Configuration (supported: fatal, error, warn, info, debug, trace | default: info)
LOG_LEVEL=


# Sentry Configuration
--------------------------------
## DO NOT CHANGE THIS UNLESS YOU KNOW WHAT YOU ARE DOING
--------------------------------
# Sentry is a tool for monitoring and logging errors and exceptions
# It is used to track errors and exceptions in the agent
--------------------------------
# Sentry Configuration
SENTRY_LOGGING=true
SENTRY_DSN=
SENTRY_ENVIRONMENT=
SENTRY_TRACES_SAMPLE_RATE=
SENTRY_SEND_DEFAULT_PII=

COINGECKO_API_KEY=CG-rwoa3iD9eMWZyw2CyobqH5oV	

### Additional Environment Variables from Runtime ###
# Variables found in process.env that were not in the template
__CFBundleIdentifier=com.apple.Terminal
TMPDIR=/var/folders/yt/ghcw_njj0q99zb5j4_0jpvvw0000gp/T/
XPC_FLAGS=0x0
TERM=xterm-256color
SSH_AUTH_SOCK=/private/tmp/com.apple.launchd.4XqXt3CItc/Listeners
XPC_SERVICE_NAME=0
TERM_PROGRAM=Apple_Terminal
TERM_PROGRAM_VERSION=453
TERM_SESSION_ID=55EC047F-40D0-4134-92A8-F573D073D104
SHELL=/bin/zsh
HOME=/Users/wildan.rahman
LOGNAME=wildan.rahman
USER=wildan.rahman
PATH=/Users/wildan.rahman/.bun/bin:/Applications/Postgres.app/Contents/Versions/latest/bin:/Users/wildan.rahman/.npm-global/bin:/Users/wildan.rahman/.nvm/versions/node/v18.20.8/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Users/wildan.rahman/.cargo/bin
SHLVL=1
PWD=/Users/wildan.rahman/Documents/Wildan
OLDPWD=/Users/wildan.rahman/Documents
HOMEBREW_PREFIX=/opt/homebrew
HOMEBREW_CELLAR=/opt/homebrew/Cellar
HOMEBREW_REPOSITORY=/opt/homebrew
INFOPATH=/opt/homebrew/share/info:
NVM_DIR=/Users/wildan.rahman/.nvm
NVM_CD_FLAGS=-q
NVM_BIN=/Users/wildan.rahman/.nvm/versions/node/v18.20.8/bin
NVM_INC=/Users/wildan.rahman/.nvm/versions/node/v18.20.8/include/node
BUN_INSTALL=/Users/wildan.rahman/.bun
LC_CTYPE=UTF-8
_=/Users/wildan.rahman/.bun/bin/elizaos
__CF_USER_TEXT_ENCODING=0x1F6:0x0:0x0
NODE_OPTIONS=--no-deprecation
NODE_NO_WARNINGS=1
PGLITE_DATA_DIR=/Users/wildan.rahman/Documents/wildan/fum-ai-agents/.eliza/.elizadb
OPENAI_API_KEY=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